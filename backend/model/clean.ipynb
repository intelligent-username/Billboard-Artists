{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9e4db5",
   "metadata": {},
   "source": [
    "# Part 1: Data Cleaning\n",
    "\n",
    "For the prediction model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0975b94",
   "metadata": {},
   "source": [
    "## Step 1: Isolate Debuts\n",
    "Database: billboard_global_200.csv<br>\n",
    "All of the Global 200 rankings on Billboard since it's beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267fed0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4325 unique songs written.\n",
      "Data cleaning phase 1 done.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "address = \"data/billboard_global_200.csv\"\n",
    "first_appearance_addy = \"data/clean1.csv\"\n",
    "\n",
    "seen = set()\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    return re.sub(r'\\s+', ' ', s.lower().strip())\n",
    "\n",
    "def canonical_key(row):\n",
    "    # row layout: [date, rank, title, main_artist, featured_artists]\n",
    "    song = normalize(row[2])\n",
    "\n",
    "    artist_blob = f\"{row[3]},{row[4]}\"\n",
    "    artists = re.split(\n",
    "        r',|&|\\+|and|feat\\.?|ft\\.?|featuring|x|with|w/',\n",
    "        artist_blob,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    artists = sorted({\n",
    "        normalize(a) for a in artists\n",
    "        if a and a.strip() and a.strip().lower() not in {\"n/a\", \"none\"}\n",
    "    })\n",
    "\n",
    "    return (song, tuple(artists))\n",
    "\n",
    "\n",
    "with open(address, 'r', encoding='utf-8') as file, \\\n",
    "     open(first_appearance_addy, 'w', newline='', encoding='utf-8') as write_file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "    writer = csv.writer(write_file)\n",
    "\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) < 5:\n",
    "            continue\n",
    "\n",
    "        key = canonical_key(row)\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(f\"{len(seen)} unique songs written.\")\n",
    "print(\"Data cleaning phase 1 done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31b470",
   "metadata": {},
   "source": [
    "## Step 2: Sweep the Data\n",
    "- Convert dates to numerical format (decades since September 5th, 2020, caps the value at 1 and still be accurate)\n",
    "- Normalize ranking (keep b/w 0 and 1), w/ #1 rank being 1 and #200 rank being 0, so greater is better.\n",
    "- Separate collaborations properly(!!!)\n",
    "- Replace N/A values (when applicable) with \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55c859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning phase 2\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import math\n",
    "import re\n",
    "\n",
    "address = \"data/clean1.csv\"\n",
    "target = \"data/clean2.csv\"\n",
    "\n",
    "columns = \"decades_since_2020_Sept,date,rank, rank_norm, title,main_artist,featured_artists\"\n",
    "\n",
    "day_one = datetime.datetime(2020, 9, 5)\n",
    "\n",
    "# Helpers\n",
    "def graft_exceptions(artist_list):\n",
    "    def is_exception(candidate):\n",
    "        # Exact-match exceptions\n",
    "        if candidate in EXCEPTIONS:\n",
    "            return True\n",
    "        # Ends with \"And His Orchestra\"\n",
    "        if candidate.endswith(\"And His Orchestra\"):\n",
    "            return True\n",
    "        # Match &-based exceptions ignoring spaces around &\n",
    "        candidate_norm = candidate.replace(' & ', '&')\n",
    "        for ex in EXCEPTIONS:\n",
    "            if ex.replace(' & ', '&') == candidate_norm:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    if len(artist_list) <= 1:\n",
    "        return artist_list\n",
    "    \n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(artist_list):\n",
    "        max_look = min(i + 4, len(artist_list))\n",
    "        found = False\n",
    "        for j in range(max_look, i, -1):\n",
    "            candidate = ' '.join(artist_list[i:j])  # <--- change here\n",
    "            if is_exception(candidate):\n",
    "                result.append(candidate)\n",
    "                i = j\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            result.append(artist_list[i])\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "def split_artists(main, sec):\n",
    "    def normalize_artists(s, sec_column_nonempty=False):\n",
    "        if not s or s.strip() in {'N/A', 'None'}:\n",
    "            return ''\n",
    "        if sec_column_nonempty:\n",
    "            s = re.sub(r'(feat\\.?|ft\\.?|featuring|Featuring)', ' feat. ', s)\n",
    "        s = re.sub(r'\\s*x\\s*', ' x ', s)\n",
    "        s = re.sub(r'(?i)(\\S)With(\\S)', r'\\1 With \\2', s)\n",
    "        s = re.sub(r'(?i)\\s*With\\s*', ' With ', s)\n",
    "        s = re.sub(r'\\s+', ' ', s)\n",
    "        return s.strip()\n",
    "\n",
    "\n",
    "    def split_names(names, is_feature=False):\n",
    "        names = normalize_artists(names)\n",
    "        if not names:\n",
    "            return []\n",
    "\n",
    "        # If the whole string matches an exception, skip splitting\n",
    "        if is_feature:\n",
    "            if names in EXCEPTIONS or names.endswith(\"And His Orchestra\"):\n",
    "                return [names]\n",
    "\n",
    "        # otherwise, split normally\n",
    "        result = [names]\n",
    "        for splitter in SPLITTERS:\n",
    "            temp = []\n",
    "            for name in result:\n",
    "                temp.extend([n.strip() for n in name.split(splitter)])\n",
    "            result = temp\n",
    "\n",
    "        seen = set()\n",
    "        unique = []\n",
    "        for n in result:\n",
    "            if n and n not in seen:\n",
    "                seen.add(n)\n",
    "                unique.append(n)\n",
    "        return graft_exceptions(unique)\n",
    "\n",
    "\n",
    "\n",
    "    main_artists = split_names(normalize_artists(main, bool(sec.strip() and sec.strip() != \"N/A\")))\n",
    "    sec_artists = split_names(normalize_artists(sec), is_feature=True)\n",
    "\n",
    "    if len(main_artists) > 1:\n",
    "        sec_artists = main_artists[1:] + sec_artists\n",
    "        main_artists = [main_artists[0]]\n",
    "\n",
    "    return main_artists, sec_artists\n",
    "\n",
    "\n",
    "with open(address, 'r', encoding='utf-8') as file, \\\n",
    "     open(target, 'w', newline='', encoding='utf-8') as write_file:\n",
    "\n",
    "    cursor = csv.reader(file)\n",
    "    writer = csv.writer(write_file)\n",
    "    writer.writerow(columns.split(','))\n",
    "    next(cursor)\n",
    "\n",
    "    SPLITTERS = [',', '&', ' + ', ' and ',\n",
    "                 ' feat. ', ' ft. ', ' featuring ', ' Featuring ',\n",
    "                 ' x ', ' X ', ' with ', ' With ', 'Duet With', 'w/', \"/\"]\n",
    "\n",
    "    EXCEPTIONS = {\n",
    "        \"Tyler, the Creator\",\n",
    "        \"Tyler, The Creator\",\n",
    "\n",
    "        \"John Scott Trotter & His Orchestra\",\n",
    "        \"Ralph Carmichael Orchestra and Chorus\",\n",
    "        \"Georgie Stoll & His Orchestra\",\n",
    "\n",
    "        \"AC/DC\",\n",
    "        \"Earth, Wind & Fire\",\n",
    "        \"TWS: 24/7\",\n",
    "        \"HUNTR/X\",\n",
    "    }\n",
    "\n",
    "    for row in cursor:\n",
    "        try:\n",
    "            date = datetime.datetime.strptime(row[0], \"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        diff = ((date - day_one).days / 3652) + 0.000001\n",
    "\n",
    "        try:\n",
    "            rank = int(row[1])\n",
    "            rank_norm = 1 / math.sqrt(rank)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        main = row[3]\n",
    "        sec = row[4]\n",
    "\n",
    "        n1, n2 = split_artists(main, sec)\n",
    "\n",
    "        main_out = f\"'{n1[0]}'\" if n1 else \"'None'\"\n",
    "        sec_out = '\"' + \", \".join([f\"'{artist}'\" for artist in n2]) + '\"' if n2 else '\"None\"'\n",
    "\n",
    "        writer.writerow([diff, row[0], row[1], rank_norm, row[2], main_out, sec_out])\n",
    "\n",
    "print(\"Finished cleaning phase 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ad52f",
   "metadata": {},
   "source": [
    "## Step 3: Engineer Some Features\n",
    "\n",
    "- Use embeddings for artist names to see which artists are closer to each other\n",
    "- Create charting recency bias (more recent data weighted more heavily), using numerical format of date\n",
    "\n",
    "**Feature Engineering**\n",
    "- For each song, aggregate the past performance of the main artist up to that point\n",
    "- For each song, aggregate the combined past performance of collaborators (again, w/ recency bias)\n",
    "\n",
    "Keep in mind release date and song title will be ignored but kept in case in the future I want to use this data.\n",
    "\n",
    "* In the future, possibly use non-debut data to examine 'longevity' of artists (might be a waste of time). That is, don't ONLY consider the debut of a given artist's songs, just consider it more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab99460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Phase 3 â€“ slower decay, stronger signal retention\n"
     ]
    }
   ],
   "source": [
    "# I think this step is by far the worst quality so far\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import re\n",
    "\n",
    "address = \"data/clean2.csv\"\n",
    "target = \"data/clean3.csv\"\n",
    "\n",
    "new_cols = \"decades_since_2020_Sept,date,rank,rank_norm,title,main_artist,featured_artists,artist_past_performance,features_past_performance\"\n",
    "\n",
    "DECAY_LAMBDA = 0.25\n",
    "FEATURES_DEFAULT = 0.1\n",
    "\n",
    "artist_pat = re.compile(r\"'([^']*)'\")\n",
    "COMMA_SPLIT = re.compile(r'\\s*,\\s*')\n",
    "\n",
    "\n",
    "def parse_time(s: str):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = s.strip()\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                return float(s[1:-1].strip())\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_main(name: str) -> str:\n",
    "    if not name:\n",
    "        return \"\"\n",
    "    return name.strip().strip(\"'\").strip()\n",
    "\n",
    "\n",
    "def parse_features(s: str) -> list[str]:\n",
    "    if not s or s in ('None', '\"None\"'):\n",
    "        return []\n",
    "    found = artist_pat.findall(s)\n",
    "    if found:\n",
    "        return [f.strip() for f in found if f.strip()]\n",
    "    inner = s[1:-1].strip() if s.startswith('\"') and s.endswith('\"') else s\n",
    "    return [p.strip().strip(\"'\").strip().strip('\"') for p in COMMA_SPLIT.split(inner) if p.strip()]\n",
    "\n",
    "\n",
    "def decay_to(t_now: float, state_tuple):\n",
    "    S, W, t0 = state_tuple\n",
    "    if t_now is None:\n",
    "        return S, W, t0\n",
    "    if t_now <= t0:\n",
    "        return S, W, t0\n",
    "    decay = math.exp(-DECAY_LAMBDA * (t_now - t0))\n",
    "    return S * decay, W * decay, t_now\n",
    "\n",
    "\n",
    "with open(address, \"r\", newline=\"\", encoding=\"utf-8\") as f_in, \\\n",
    "     open(target, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "\n",
    "    reader = csv.reader(f_in)\n",
    "    writer = csv.writer(f_out)\n",
    "    writer.writerow([c.strip() for c in new_cols.split(\",\")])\n",
    "    next(reader, None)  # skip header\n",
    "\n",
    "    rows = list(reader)\n",
    "\n",
    "    # stable chronological sort\n",
    "    def sort_key(row):\n",
    "        t = parse_time(row[0])\n",
    "        t_sort = t if t is not None else float(\"inf\")\n",
    "        date = row[1] if len(row) > 1 else \"\"\n",
    "        try:\n",
    "            rank_int = int(row[2]) if len(row) > 2 and row[2].strip() != \"\" else 9999\n",
    "        except:\n",
    "            rank_int = 9999\n",
    "        return (t_sort, date, rank_int)\n",
    "\n",
    "    rows.sort(key=sort_key)\n",
    "\n",
    "    state = {}\n",
    "\n",
    "    for row in rows:\n",
    "        if len(row) < 7:\n",
    "            continue\n",
    "\n",
    "        t = parse_time(row[0])\n",
    "        if t is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            r_norm = float(row[3])\n",
    "        except:\n",
    "            try:\n",
    "                rank_raw = int(row[2])\n",
    "                r_norm = 1.0 / math.sqrt(rank_raw) if rank_raw > 0 else 0.5\n",
    "            except:\n",
    "                r_norm = 0.5\n",
    "\n",
    "        main = parse_main(row[5])\n",
    "        feats = parse_features(row[6])\n",
    "\n",
    "        S_m, W_m, _ = decay_to(t, state.get(main, (0.0, 0.0, t)))\n",
    "        main_perf = (S_m / W_m) if W_m > 1e-8 else 0.5\n",
    "\n",
    "        feat_perfs = []\n",
    "        for a in feats:\n",
    "            S_a, W_a, _ = decay_to(t, state.get(a, (0.0, 0.0, t)))\n",
    "            feat_perfs.append((S_a / W_a) if W_a > 1e-8 else 0.5)\n",
    "        feats_perf = (sum(feat_perfs) / len(feat_perfs)) if feat_perfs else FEATURES_DEFAULT\n",
    "\n",
    "        writer.writerow(row + [main_perf, feats_perf])\n",
    "\n",
    "        for a in {main, *feats}:\n",
    "            S0, W0, t0 = state.get(a, (0.0, 0.0, t))\n",
    "            S0, W0, _ = decay_to(t, (S0, W0, t0))\n",
    "            S0 += r_norm\n",
    "            W0 += 1.0\n",
    "            last_time = max(t, t0)\n",
    "            state[a] = (S0, W0, last_time)\n",
    "\n",
    "print(\"Finished Phase 3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
